{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d4ed7d-6012-4830-bcac-9b89a4a415a3",
   "metadata": {},
   "source": [
    "# **Ingenier√≠a de Caracter√≠sticas - `05_ingenieria_caracteristicas.ipynb`**\n",
    "\n",
    "### **üéØ Objetivo del Notebook**\n",
    "Este notebook tiene como objetivo aplicar t√©cnicas de **ingenier√≠a de caracter√≠sticas** sobre las se√±ales EEG, con el fin de capturar mejor la informaci√≥n contenida en las se√±ales y mejorar el rendimiento de los modelos de clasificaci√≥n.\n",
    "\n",
    "### **üìå Contexto**\n",
    "En el notebook anterior (`04_analisis_caracteristicas.ipynb`), analizamos la importancia de las caracter√≠sticas existentes y aplicamos varias t√©cnicas de selecci√≥n y reducci√≥n de dimensionalidad. Sin embargo, concluimos que:\n",
    "\n",
    "- La **eliminaci√≥n de outliers** fue el √∫nico preprocesamiento que mejor√≥ el rendimiento.\n",
    "- La **selecci√≥n de caracter√≠sticas** y **reducci√≥n de dimensionalidad** no s√≥lo no aportaron mejoras, sino que en muchos casos **empeoraron los resultados**.\n",
    "\n",
    "Dado que los datos EEG son se√±ales **temporales complejas**, y que el modelo actual no logra capturar suficientemente su estructura din√°mica con las caracter√≠sticas crudas, es necesario **generar nuevas variables** que representen mejor la informaci√≥n relevante en la se√±al.\n",
    "\n",
    "---\n",
    "\n",
    "### **üß† ¬øPor qu√© Ingenier√≠a de Caracter√≠sticas?**\n",
    "\n",
    "Incluso los mejores modelos no pueden rendir bien si no se les alimenta con datos representativos. Por eso, vamos a construir nuevas variables derivadas de las se√±ales originales que puedan captar:\n",
    "\n",
    "- Tendencias locales (media m√≥vil)\n",
    "- Cambios r√°pidos (derivadas o gradientes)\n",
    "- Patrones en el dominio de la frecuencia (FFT)\n",
    "- Niveles de variabilidad o actividad (desviaci√≥n est√°ndar, rango, energ√≠a)\n",
    "\n",
    "Estas transformaciones buscan **extraer informaci√≥n latente** que no es evidente en las se√±ales brutas.\n",
    "\n",
    "---\n",
    "\n",
    "### **üöÄ Flujo de Trabajo en este Notebook**\n",
    "1Ô∏è‚É£ **Carga de datos**    \n",
    "2Ô∏è‚É£ **Definici√≥n de ventanas temporales para extracci√≥n de caracter√≠sticas**    \n",
    "3Ô∏è‚É£ **C√°lculo de estad√≠sticas temporales (media, std, varianza, gradiente)**  \n",
    "4Ô∏è‚É£ **Aplicaci√≥n de transformadas en frecuencia (FFT, potencia espectral)**  \n",
    "5Ô∏è‚É£ **Generaci√≥n de nuevas variables y construcci√≥n de un nuevo conjunto de datos**  \n",
    "6Ô∏è‚É£ **Evaluaci√≥n del impacto en el rendimiento del modelo**  \n",
    "7Ô∏è‚É£ **Conclusi√≥n sobre qu√© variables se mantienen y pr√≥ximos pasos**\n",
    "\n",
    "*Cargamos los datos sin preprocesar y eliminamos `outliers` pero todav√≠a no normalizamos ya que las transformaciones que haremos, como calcular medias, desviaciones, FFT o energ√≠a, dependen de la forma y magnitud original de la se√±al. Si normaliz√°ramos antes, perder√≠amos esa informaci√≥n significativa. Por eso, aplicaremos la normalizaci√≥n despu√©s de extraer las nuevas caracter√≠sticas.\n",
    "\n",
    "---\n",
    "\n",
    "üìå Si estas nuevas variables aportan mejoras, las incorporaremos como parte del preprocesamiento final antes de probar modelos m√°s avanzados como **XGBoost, LightGBM o Redes Neuronales**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c524f2-2568-4e9f-b433-dc85af06a191",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c6efad-76da-4586-8397-6c155551a57a",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72fed2-d74f-47ef-be07-f2dff73fdf35",
   "metadata": {},
   "source": [
    "## **1. Carga de datos y Eliminaci√≥n Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb0df3c-1b59-41bd-a169-681246e8b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_filtered shape: (1043205, 32)\n",
      "y_train_filtered shape: (1043205, 6)\n",
      "X_valid shape: (236894, 32)\n",
      "y_valid shape: (236894, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\luciaft\\Documents\\TFG\\TFG\\graspAndLiftDetectionTFGProyect\\data\\raw_data\\train\\train\"\n",
    "SUBJECT = \"subj1\"\n",
    "SERIES_TRAIN = [f\"{SUBJECT}_series{i}_data.csv\" for i in range(1, 9)]\n",
    "SERIES_EVENTS = [f\"{SUBJECT}_series{i}_events.csv\" for i in range(1, 9)]\n",
    "\n",
    "def load_data(series, path=DATA_PATH):\n",
    "    dfs = [pd.read_csv(os.path.join(path, file)) for file in series]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_train = load_data(SERIES_TRAIN)\n",
    "df_events = load_data(SERIES_EVENTS)\n",
    "df = df_train.merge(df_events, on=\"id\")\n",
    "\n",
    "eeg_columns = df.columns[1:33]  # Columnas de se√±ales EEG\n",
    "event_columns = [\"HandStart\", \"FirstDigitTouch\", \"BothStartLoadPhase\", \"LiftOff\", \"Replace\", \"BothReleased\"]\n",
    "\n",
    "df_sujeto1 = df[df[\"id\"].str.startswith(\"subj1_series\")]\n",
    "df_train = df_sujeto1[df_sujeto1[\"id\"].str.contains(\"series[1-6]_\")]\n",
    "df_valid = df_sujeto1[df_sujeto1[\"id\"].str.contains(r\"series[7-8]_\", regex=True)]\n",
    "\n",
    "X_train, y_train = df_train[eeg_columns], df_train[event_columns]\n",
    "X_valid, y_valid = df_valid[eeg_columns], df_valid[event_columns]\n",
    "\n",
    "# Eliminaci√≥n de Outliers\n",
    "z_scores = np.abs(zscore(X_train))\n",
    "outlier_threshold = 3\n",
    "mask = (z_scores < outlier_threshold).all(axis=1)\n",
    "X_train_filtered = X_train[mask]\n",
    "y_train_filtered = y_train[mask]\n",
    "\n",
    "print(f\"X_train_filtered shape: {X_train_filtered.shape}\")\n",
    "print(f\"y_train_filtered shape: {y_train_filtered.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669c5da-50f4-485a-b07c-1e0cce7e3c7d",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923cb74-22b7-4d0e-84de-1735d0f17544",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07c008-4163-4836-8bb5-7745968302cf",
   "metadata": {},
   "source": [
    "## **2. Creaci√≥n Ventanas Temporales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a93ca4-1726-448a-80c4-969db7cf2a55",
   "metadata": {},
   "source": [
    "Las ventanas sirven para dividir la se√±al EEG continua en segmentos cortos que nos permiten extraer estad√≠sticas (como media, energ√≠a o frecuencia) en intervalos de tiempo. As√≠ captamos c√≥mo cambia la actividad cerebral antes, durante y despu√©s de un evento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201312df-a95a-4158-b8ec-c0b98080e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventanas creadas:\n",
      "X_train_win shape: (16299, 128, 32)\n",
      "y_train_win shape: (16299, 6)\n"
     ]
    }
   ],
   "source": [
    "# Par√°metros\n",
    "window_size = 128  # duraci√≥n de la ventana\n",
    "step_size = 64     # paso entre ventanas\n",
    "\n",
    "def create_windows(X, y, window_size, step_size):\n",
    "    X_windows, y_windows = [], []\n",
    "    for i in range(0, X.shape[0] - window_size, step_size):\n",
    "        window = X.iloc[i:i+window_size]\n",
    "        label = y.iloc[i + window_size//2]  # tomamos la etiqueta del centro\n",
    "        X_windows.append(window)\n",
    "        y_windows.append(label)\n",
    "    return np.array(X_windows), pd.DataFrame(y_windows, columns=y.columns)\n",
    "\n",
    "X_train_win, y_train_win = create_windows(X_train_filtered, y_train_filtered, window_size, step_size)\n",
    "X_valid_win, y_valid_win = create_windows(X_valid, y_valid, window_size, step_size)\n",
    "\n",
    "print(\"Ventanas creadas:\")\n",
    "print(f\"X_train_win shape: {X_train_win.shape}\")\n",
    "print(f\"y_train_win shape: {y_train_win.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7806455-17e6-42f2-8336-0624350e7cf0",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce9f29-8f43-42b5-9b77-eb066b2880b8",
   "metadata": {},
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9daecfa-08de-4e0d-aeb6-b11c52c5adfd",
   "metadata": {},
   "source": [
    "## **3. Extraer Estad√≠sticas Temporales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9c326-d0b9-4083-8342-414a7755c611",
   "metadata": {},
   "source": [
    "**Para cada ventana y cada canal EEG vamos a sacar:**\n",
    "- Media\n",
    "- Desviaci√≥n est√°ndar\n",
    "- M√≠nimo y m√°ximo\n",
    "- Rango (max - min)\n",
    "- Mediana\n",
    "- Percentiles 25 y 75\n",
    "- Gradiente medio\n",
    "- Asimetr√≠a (skewness)\n",
    "- Curtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33225760-0d9d-49f8-9272-bb5f81429f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas caracter√≠sticas extra√≠das:\n",
      "X_train_feats shape: (16299, 352)\n"
     ]
    }
   ],
   "source": [
    "def extract_time_features(X_windows):\n",
    "    features = []\n",
    "    for window in X_windows:\n",
    "        stats = []\n",
    "        for ch in window.T:  # recorremos canales\n",
    "            ch_series = pd.Series(ch)\n",
    "            stats.extend([\n",
    "                ch_series.mean(),\n",
    "                ch_series.std(),\n",
    "                ch_series.min(),\n",
    "                ch_series.max(),\n",
    "                ch_series.max() - ch_series.min(),  # rango\n",
    "                ch_series.median(),\n",
    "                ch_series.quantile(0.25),\n",
    "                ch_series.quantile(0.75),\n",
    "                np.gradient(ch).mean(),\n",
    "                ch_series.skew(),\n",
    "                ch_series.kurt()\n",
    "            ])\n",
    "        features.append(stats)\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_feats = extract_time_features(X_train_win)\n",
    "X_valid_feats = extract_time_features(X_valid_win)\n",
    "\n",
    "print(\"Nuevas caracter√≠sticas extra√≠das:\")\n",
    "print(f\"X_train_feats shape: {X_train_feats.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb186311-3f81-45c6-9468-69de1ef82aba",
   "metadata": {},
   "source": [
    "### **Versi√≥n optimizada del extractor temporal:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d31d06-65fa-46be-945d-4a4c216573de",
   "metadata": {},
   "source": [
    "Dado que el proceso de extracci√≥n de caracter√≠sticas temporales tardaba demasiado, optimizamos el c√≥digo utilizando funciones m√°s r√°pidas y vectorizadas, como `numpy` y `scipy.stats` en lugar de `pandas`. Esto permiti√≥ reducir significativamente el tiempo de c√≥mputo sin perder precisi√≥n en los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c54d9c2-08d3-4df5-8cd4-03730d29b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas caracter√≠sticas extra√≠das:\n",
      "X_train_feats shape: (16299, 352)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_time_features_fast(X_windows):\n",
    "    features = []\n",
    "    for window in X_windows:\n",
    "        stats = []\n",
    "        for ch in window.T:\n",
    "            stats.extend([\n",
    "                np.mean(ch),\n",
    "                np.std(ch),\n",
    "                np.min(ch),\n",
    "                np.max(ch),\n",
    "                np.ptp(ch),  # rango: max - min\n",
    "                np.median(ch),\n",
    "                np.percentile(ch, 25),\n",
    "                np.percentile(ch, 75),\n",
    "                np.mean(np.gradient(ch)),\n",
    "                skew(ch),           # scipy (m√°s r√°pido)\n",
    "                kurtosis(ch)        # scipy (m√°s r√°pido)\n",
    "            ])\n",
    "        features.append(stats)\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_feats = extract_time_features_fast(X_train_win)\n",
    "X_valid_feats = extract_time_features_fast(X_valid_win)\n",
    "\n",
    "print(\"Nuevas caracter√≠sticas extra√≠das:\")\n",
    "print(f\"X_train_feats shape: {X_train_feats.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f191c02-a962-4081-b6c3-258c4b6fc3a4",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e731f-a838-4f06-ba52-501e32b60a41",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1a9e0-8d5d-4e18-978c-647f7e4763dc",
   "metadata": {},
   "source": [
    "## **4. Extraer Caracter√≠sticas en Frecuencia (FFT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd5303-fc84-4930-82e4-2e4c5e05b584",
   "metadata": {},
   "source": [
    "El cerebro se comunica en diferentes frecuencias (ondas delta, theta, alfa, beta...), la FFT ayuda a ver qu√© tan activas est√°n esas bandas durante cada ventana. Al trabajar con se√±ales EEG, es fundamental capturar informaci√≥n tanto en el dominio temporal como en el de frecuencia. Para ello, en lugar de usar una FFT directa, utilizamos el m√©todo de Welch (`scipy.signal.welch`), que estima la potencia espectral de forma m√°s estable y robusta frente al ruido. Esto nos permite calcular de forma m√°s fiable la energ√≠a presente en las bandas caracter√≠sticas del EEG (delta, theta, alfa y beta), generando variables m√°s representativas para los modelos de clasificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa087b0e-1f70-4a33-9658-162183c925dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracter√≠sticas en frecuencia extra√≠das:\n",
      "X_train_freq shape: (16299, 160)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "def extract_freq_features(X_windows, fs=128):\n",
    "    freq_feats = []\n",
    "    for window in X_windows:\n",
    "        features = []\n",
    "        for ch in window.T:\n",
    "            freqs, psd = welch(ch, fs=fs, nperseg=128)\n",
    "            bands = {\n",
    "                'delta': (0.5, 4),\n",
    "                'theta': (4, 8),\n",
    "                'alpha': (8, 13),\n",
    "                'beta': (13, 30)\n",
    "            }\n",
    "            for low, high in bands.values():\n",
    "                band_power = np.sum(psd[(freqs >= low) & (freqs < high)])\n",
    "                features.append(band_power)\n",
    "            features.append(np.sum(psd))  # energ√≠a total\n",
    "        freq_feats.append(features)\n",
    "    return np.array(freq_feats)\n",
    "\n",
    "X_train_freq = extract_freq_features(X_train_win)\n",
    "X_valid_freq = extract_freq_features(X_valid_win)\n",
    "\n",
    "print(\"Caracter√≠sticas en frecuencia extra√≠das:\")\n",
    "print(f\"X_train_freq shape: {X_train_freq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293ca87-2295-49be-a0e3-237bb7260f6c",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6473552-dbbc-4019-adf2-9931ae26b4f1",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93740150-a81f-4648-975f-bfe631af1527",
   "metadata": {},
   "source": [
    "## **5. Generaci√≥n Nuevas Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cce6fd-c28d-44f8-a170-f457f9afb0ab",
   "metadata": {},
   "source": [
    "Unimos los datos de las estad√≠sticas temporales y de las caracter√≠sticas en frecuencia, y normalizamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a252d3c6-ee50-4c31-896a-940f1225cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.concatenate([X_train_feats, X_train_freq], axis=1)\n",
    "X_valid_final = np.concatenate([X_valid_feats, X_valid_freq], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251737fb-7477-405f-b90a-f81c473d70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_valid_scaled = scaler.transform(X_valid_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe6938-3727-409a-9dd1-083c2e29db30",
   "metadata": {},
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a06032-1b18-4f67-9e5c-68a376bd7d0c",
   "metadata": {},
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4759a96-1a40-44fb-a73c-5398b9a2da47",
   "metadata": {},
   "source": [
    "## **6. Entrenar y Evaluar Modelos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "905c17ba-1737-45b9-b512-a44c632828b9",
   "metadata": {},
   "source": [
    "Finalmente entrenamos con estas nuevas variables el modelo base que hasta ahora mejores resultados ha demostrado, **Regresi√≥n Log√≠stica**, y lo evaluamos para verificar si estas nuevas caracter√≠sticas realmente mejoran el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73696a3-31b0-4183-8031-92f6b9726caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando evento: HandStart\n",
      "HandStart: AUC = 0.9539\n",
      "\n",
      "Evaluando evento: FirstDigitTouch\n",
      "FirstDigitTouch: AUC = 0.9040\n",
      "\n",
      "Evaluando evento: BothStartLoadPhase\n",
      "BothStartLoadPhase: AUC = 0.9404\n",
      "\n",
      "Evaluando evento: LiftOff\n",
      "LiftOff: AUC = 0.8833\n",
      "\n",
      "Evaluando evento: Replace\n",
      "Replace: AUC = 0.8892\n",
      "\n",
      "Evaluando evento: BothReleased\n",
      "BothReleased: AUC = 0.8587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_valid, y_valid, event_name):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "    auc = roc_auc_score(y_valid, y_pred)\n",
    "    print(f\"{event_name}: AUC = {auc:.4f}\")\n",
    "    return auc\n",
    "\n",
    "# Evaluaci√≥n por evento\n",
    "for i, event in enumerate(y_train_win.columns):\n",
    "    print(f\"\\nEvaluando evento: {event}\")\n",
    "    auc = evaluate_model(\n",
    "        X_train_scaled, y_train_win[event],\n",
    "        X_valid_scaled, y_valid_win[event],\n",
    "        event\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff99de7-7d87-4125-b2d2-91f72abeeefb",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec437e-c636-46bd-a091-ad327ddcd1fa",
   "metadata": {},
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6122c4eb-3f6e-4197-a369-c89b6fe08b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ruta de guardado\n",
    "processed_path = r\"C:\\Users\\luciaft\\Documents\\TFG\\TFG\\graspAndLiftDetectionTFGProyect\\data\\processed\"\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "# Guardar datos preprocesados finales (w/o outliers + features temporales + frecuencia + escalado)\n",
    "with open(os.path.join(processed_path, \"preprocessed_features_temporal_freq.pkl\"), \"wb\") as f:\n",
    "    pickle.dump((X_train_scaled, y_train_win, X_valid_scaled, y_valid_win), f)\n",
    "\n",
    "# Guardar en CSV para visualizaci√≥n r√°pida si hace falta\n",
    "pd.DataFrame(X_train_scaled).to_csv(os.path.join(processed_path, \"X_train_feats.csv\"), index=False)\n",
    "pd.DataFrame(y_train_win).to_csv(os.path.join(processed_path, \"y_train_feats.csv\"), index=False)\n",
    "pd.DataFrame(X_valid_scaled).to_csv(os.path.join(processed_path, \"X_valid_feats.csv\"), index=False)\n",
    "pd.DataFrame(y_valid_win).to_csv(os.path.join(processed_path, \"y_valid_feats.csv\"), index=False)\n",
    "\n",
    "# Guardar resultados AUC del modelo actual\n",
    "auc_dict = {\n",
    "    \"HandStart\": 0.9539,\n",
    "    \"FirstDigitTouch\": 0.9040,\n",
    "    \"BothStartLoadPhase\": 0.9404,\n",
    "    \"LiftOff\": 0.8833,\n",
    "    \"Replace\": 0.8892,\n",
    "    \"BothReleased\": 0.8587\n",
    "}\n",
    "\n",
    "auc_df = pd.DataFrame.from_dict(auc_dict, orient='index', columns=['AUC'])\n",
    "auc_df.index.name = 'Evento'\n",
    "auc_df.to_csv(os.path.join(processed_path, \"auc_results_feats_logreg.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a74893-7e3b-446c-b8c7-4677c8aa1441",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f67bd6-ca5c-48e7-90b4-35cf472d8ab2",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec86558-9345-4073-893e-3ec42c534eb6",
   "metadata": {},
   "source": [
    "## üìå **Conclusi√≥n y Pr√≥ximos Pasos**\n",
    "### Comparaci√≥n de Rendimiento: Antes vs Despu√©s de Ingenier√≠a de Caracter√≠sticas\n",
    "\n",
    "Comprobamos si las nuevas variables generadas (estad√≠sticas temporales + frecuencia mediante potencia espectral) mejoran el rendimiento del modelo. A continuaci√≥n, se comparan los valores de AUC-ROC obtenidos con:\n",
    "\n",
    "- **Datos preprocesados √∫nicamente eliminando outliers y normalizando**\n",
    "- **Nuevas caracter√≠sticas extra√≠das y normalizadas**\n",
    "\n",
    "| Evento                | AUC (antes) | AUC (con nuevas caracter√≠sticas) |\n",
    "|-----------------------|-------------|----------------------------------|\n",
    "| HandStart             | 0.718       | 0.9539                           |\n",
    "| FirstDigitTouch       | 0.694       | 0.9040                           |\n",
    "| BothStartLoadPhase    | 0.6922      | 0.9404                           |\n",
    "| LiftOff               | 0.7462      | 0.8833                           |\n",
    "| Replace               | 0.8501      | 0.8892                           |\n",
    "| BothReleased          | 0.808       | 0.8587                           |\n",
    "\n",
    "üü¢ **Conclusi√≥n**: Las nuevas caracter√≠sticas extra√≠das mejoran de forma clara y consistente el rendimiento del modelo en todos los eventos. Se observa un aumento especialmente significativo en eventos como *HandStart* y *BothStartLoadPhase*, donde se alcanzan valores superiores a 0.94 en AUC-ROC. Por tanto, estas nuevas variables se incorporar√°n al pipeline final de modelado. Tras mostrarse los resultados, se han guardado los datos preprocesados para ser utilizados en el siguiente notebook con modelos avanzados.\n",
    "\n",
    "### ‚úÖ Preprocesado Completo\n",
    "\n",
    "El conjunto de datos final preparado para entrenar modelos incluye los siguientes pasos:\n",
    "\n",
    "- **Filtrado de outliers**: Eliminaci√≥n de muestras extremas en el conjunto de entrenamiento mediante z-score (no se eliminan en validaci√≥n).\n",
    "- **Divisi√≥n en ventanas temporales**: Cada ventana representa 1 segundo de EEG (128 muestras) con un solapamiento del 50%.\n",
    "- **Extracci√≥n de caracter√≠sticas**: Por cada ventana y canal se calcularon:\n",
    "  - Estad√≠sticas temporales: media, desviaci√≥n est√°ndar, percentiles, rango, gradiente, skewness, kurtosis, etc.\n",
    "  - Caracter√≠sticas en frecuencia: energ√≠a espectral en bandas delta, theta, alpha, beta y energ√≠a total.\n",
    "- **Normalizaci√≥n**: Se aplic√≥ `StandardScaler` sobre las variables extra√≠das para estandarizarlas (media 0, varianza 1).\n",
    "- **Alineaci√≥n correcta con etiquetas**: Las etiquetas (`y_train_win`) se tomaron del centro de cada ventana, manteniendo la correspondencia temporal con los eventos.\n",
    "\n",
    "---\n",
    "\n",
    "### Pr√≥ximos pasos - Notebook **`06_modelado_avanzado`**\n",
    "\n",
    "En el siguiente notebook entrenaremos modelos m√°s potentes para mejorar el rendimiento,  como:\n",
    "   - `RandomForestClassifier`\n",
    "   - `XGBoost`\n",
    "   - `LightGBM`\n",
    "   - Redes neuronales con `Keras`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
